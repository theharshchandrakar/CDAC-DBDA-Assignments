{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1316cef",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d548e7",
   "metadata": {},
   "source": [
    "PRN: 250840125020 (Harsh Chandrakar)  \n",
    "PRN: 250840125052 (Sumit Nagpure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ff1306",
   "metadata": {},
   "source": [
    "## 1. Load data and basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6be1d788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "f0ec291e-a5a5-40a3-bd3a-d1dbf65b1c03",
       "rows": [
        [
         "Item_Identifier",
         "0"
        ],
        [
         "Item_Weight",
         "1463"
        ],
        [
         "Item_Fat_Content",
         "0"
        ],
        [
         "Item_Visibility",
         "0"
        ],
        [
         "Item_Type",
         "0"
        ],
        [
         "Item_MRP",
         "0"
        ],
        [
         "Outlet_Identifier",
         "0"
        ],
        [
         "Outlet_Establishment_Year",
         "0"
        ],
        [
         "Outlet_Size",
         "2410"
        ],
        [
         "Outlet_Location_Type",
         "0"
        ],
        [
         "Outlet_Type",
         "0"
        ],
        [
         "Item_Outlet_Sales",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 12
       }
      },
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                  1463\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  2410\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head()\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a69baf",
   "metadata": {},
   "source": [
    "\n",
    "Typical cleaning for this dataset (same Big Mart problem).[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d444adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "\n",
    "# 1) Standardize Item_Fat_Content\n",
    "data['Item_Fat_Content'] = data['Item_Fat_Content'].replace(\n",
    "    {'LF': 'Low Fat', 'low fat': 'Low Fat', 'reg': 'Regular'}\n",
    ")\n",
    "\n",
    "# 2) Impute Item_Weight\n",
    "data['Item_Weight'] = data.groupby('Item_Identifier')['Item_Weight']\\\n",
    "                          .transform(lambda x: x.fillna(x.mean()))\n",
    "data['Item_Weight'] = data['Item_Weight'].fillna(data['Item_Weight'].mean())\n",
    "\n",
    "# 3) Impute Outlet_Size by most frequent size per Outlet_Type\n",
    "data['Outlet_Size'] = data.groupby('Outlet_Type')['Outlet_Size']\\\n",
    "                          .transform(lambda x: x.fillna(x.mode()[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26041d8",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Drop composite key and prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5057669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = 'Item_Outlet_Sales'\n",
    "drop_cols = ['Item_Identifier', 'Outlet_Identifier']  # composite key\n",
    "\n",
    "X = data.drop(columns=drop_cols + [target])\n",
    "y = data[target]\n",
    "\n",
    "# One‑hot encode categoricals\n",
    "X = pd.get_dummies(X, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6006373",
   "metadata": {},
   "source": [
    "## 3. Train–test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93301595",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52aab7d",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Build 3 models and evaluate\n",
    "\n",
    "Use RMSE as the metric (common for this problem).[2][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5894f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23387a5",
   "metadata": {},
   "source": [
    "\n",
    "### Model 1: Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ef3eefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 1145541.8463362118\n",
      "Linear Regression R2: 0.5785303670536149\n"
     ]
    }
   ],
   "source": [
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train)\n",
    "\n",
    "pred_lin = lin.predict(X_test)\n",
    "rmse_lin = mean_squared_error(y_test, pred_lin)\n",
    "print(\"Linear Regression RMSE:\", rmse_lin)\n",
    "print(\"Linear Regression R2:\", r2_score(y_test, pred_lin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61dda46",
   "metadata": {},
   "source": [
    "\n",
    "### Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a0deb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 1117818.4312321786\n",
      "Linear Regression R2: 0.5887304113604099\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=12,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "pred_rf = rf.predict(X_test)\n",
    "rmse_rf = mean_squared_error(y_test, pred_rf)\n",
    "print(\"Random Forest RMSE:\", rmse_rf)\n",
    "print(\"Linear Regression R2:\", r2_score(y_test, pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1c17d0",
   "metadata": {},
   "source": [
    "### Model 3: Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a690e6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting RMSE: 1081640.6838566265\n",
      "Linear Regression R2: 0.6020409874480214\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "pred_gb = gb.predict(X_test)\n",
    "rmse_gb = mean_squared_error(y_test, pred_gb)\n",
    "print(\"Gradient Boosting RMSE:\", rmse_gb)\n",
    "print(\"Linear Regression R2:\", r2_score(y_test, pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b021e51",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "<!-- In this project, the Big Mart Sales dataset was cleaned by imputing missing values for `Item_Weight` and `Outlet_Size`, and by standardizing inconsistent category labels such as `Item_Fat_Content`. Composite key columns `Item_Identifier` and `Outlet_Identifier` were excluded from the feature set, and the remaining categorical variables were one‑hot encoded before performing a train–test split. Three regression models—Linear Regression, Random Forest, and Gradient Boosting—were trained and evaluated using RMSE on the test set, where the tree‑based ensemble models outperformed the linear baseline, indicating that non‑linear relationships and feature interactions are important for accurately predicting `Item_Outlet_Sales` in this dataset. -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1beafb",
   "metadata": {},
   "source": [
    "Final Summary\n",
    "In this project, I took the Big Mart sales data and `cleaned` it by filling in gaps and fixing typos. Once the data was ready, I put it through three different models to see which one was the best at predicting future sales.\n",
    "\n",
    "The `Random Forest` and `Gradient Boosting` models came out on top, beating the basic `Linear Regression model`. This tells us that predicting sales is a bit complicated—factors like the type of item and the size of the store interact in ways that require these more advanced \"AI\" models to get an accurate result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2661e225",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
